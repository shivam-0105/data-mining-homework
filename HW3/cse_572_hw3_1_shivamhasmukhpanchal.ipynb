{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CSE 572 - Data Mining\n",
        "\n",
        "## Homework - 3\n",
        "\n",
        "### Name : Shivam Hasmukh Panchal\n",
        "### ASU ID : 1229664308\n",
        "\n",
        "### Task - 1"
      ],
      "metadata": {
        "id": "j5Be00KUJTic"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5P4BwludHbxW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random as rand\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data.csv\").to_numpy()\n",
        "labels = pd.read_csv(\"label.csv\",header = None).to_numpy().flatten()"
      ],
      "metadata": {
        "id": "puOIknpXHyDl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_centroids(data, K):\n",
        "    centroids = []\n",
        "\n",
        "    for i in range(K):\n",
        "        centroid = data[rand.randint(0, 149)]\n",
        "        centroids.append(centroid)\n",
        "    return centroids\n",
        "\n",
        "\n",
        "def assign_cluster(data, centroids):\n",
        "    assignments = []\n",
        "\n",
        "    for data_point in data:\n",
        "        dist_point_clust = []\n",
        "\n",
        "        for centroid in centroids:\n",
        "            d_clust = np.linalg.norm(np.array(data_point) - np.array(centroid))\n",
        "            dist_point_clust.append(d_clust)\n",
        "\n",
        "        assignment = np.argmin(dist_point_clust)\n",
        "        assignments.append(assignment)\n",
        "\n",
        "    return assignments\n",
        "\n",
        "def new_centroids(data, centroids, assignments, K):\n",
        "    new_centroids = []\n",
        "    for i in range(K):\n",
        "        pt_cluster = []\n",
        "        for x in range(len(data)):\n",
        "                if (assignments[x] == i):\n",
        "                    pt_cluster.append(data[x])\n",
        "        mean_c = np.mean(pt_cluster, axis=0)\n",
        "        new_centroids.append(mean_c)\n",
        "\n",
        "    return new_centroids\n",
        "\n",
        "def sse(data, assignments, centroids):\n",
        "    errors = []\n",
        "\n",
        "    for i in range(len(data)):\n",
        "\n",
        "        centroid = centroids[assignments[i]]\n",
        "        error = np.linalg.norm(np.array(data[i]) - np.array(centroid))\n",
        "        errors.append(error**2)\n",
        "\n",
        "    sse = sum(errors)\n",
        "\n",
        "    return sse"
      ],
      "metadata": {
        "id": "9bo6LhKCILSs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(x1, x2):\n",
        "    return np.linalg.norm(x1 - x2)\n",
        "\n",
        "def cosine_similarity(x1, x2):\n",
        "    dot_product = np.dot(x1, x2)\n",
        "    norm_x1 = np.linalg.norm(x1)\n",
        "    norm_x2 = np.linalg.norm(x2)\n",
        "    similarity = dot_product / (norm_x1 * norm_x2)\n",
        "    return 1 - similarity\n",
        "\n",
        "def jaccard_similarity(x1, x2):\n",
        "    intersection = np.sum(np.minimum(x1, x2))\n",
        "    union = np.sum(np.maximum(x1, x2))\n",
        "    similarity = intersection / union\n",
        "    return 1 - similarity\n",
        "\n",
        "\n",
        "def k_means(data, k, distance_function, max_iters=100):\n",
        "    n_samples, n_features = data.shape\n",
        "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
        "    labels = np.zeros(n_samples)\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        for i in range(n_samples):\n",
        "            distances = [distance_function(data[i], centroid) for centroid in centroids]\n",
        "            labels[i] = np.argmin(distances)\n",
        "\n",
        "\n",
        "        for j in range(k):\n",
        "            mask = labels == j\n",
        "            centroids[j] = np.mean(data[mask], axis=0)\n",
        "\n",
        "    sse = sum([distance_function(data[i], centroids[int(labels[i])])**2 for i in range(n_samples)])\n",
        "\n",
        "    return labels, centroids, sse\n",
        "\n",
        "data = pd.read_csv(\"data.csv\",header = None).to_numpy()\n",
        "labels = pd.read_csv(\"label.csv\",header = None).to_numpy()\n",
        "\n",
        "# Set the number of clusters (k)\n",
        "k = len(np.unique(labels))  # Number of categories in label\n",
        "\n",
        "distance_functions = [euclidean_distance, cosine_similarity, jaccard_similarity]\n",
        "distance_function_names = ['Euclidean', 'Cosine', 'Jaccard']\n",
        "\n",
        "results = {}\n",
        "\n",
        "\n",
        "for distance_function, distance_function_name in zip(distance_functions, distance_function_names):\n",
        "\n",
        "    cluster_labels, cluster_centroids, sse = k_means(data, k, distance_function)\n",
        "    accuracy = np.sum(cluster_labels == labels.squeeze()) / len(labels)\n",
        "    results[distance_function_name] = {'SSE': sse, 'Accuracy': accuracy}\n",
        "\n",
        "for method, result in results.items():\n",
        "    print(f\"{method} K-means - SSE: {result['SSE']:.2f}, Accuracy: {result['Accuracy'] * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_K2_laIPug",
        "outputId": "ab55a2ae-d1a1-4519-eec6-00a13be78d5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean K-means - SSE: 25452038998.00, Accuracy: 2.21%\n",
            "Cosine K-means - SSE: 697.80, Accuracy: 16.13%\n",
            "Jaccard K-means - SSE: 3654.21, Accuracy: 8.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data.csv\", header=None).to_numpy()\n",
        "labels = pd.read_csv(\"label.csv\", header=None).to_numpy().flatten()\n",
        "\n",
        "def k_means_majority_vote(data, k, distance_function, max_iters=100):\n",
        "    n_samples, n_features = data.shape\n",
        "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
        "    assigned_labels = np.zeros(n_samples)\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        for i in range(n_samples):\n",
        "            distances = [distance_function(data[i], centroid) for centroid in centroids]\n",
        "            assigned_labels[i] = np.argmin(distances)\n",
        "\n",
        "        for j in range(k):\n",
        "            mask = assigned_labels == j\n",
        "            centroids[j] = np.mean(data[mask], axis=0)\n",
        "\n",
        "    # Label each cluster using majority vote\n",
        "    cluster_labels = np.zeros(k)\n",
        "    for j in range(k):\n",
        "        cluster_mask = assigned_labels == j\n",
        "        majority_label = np.argmax(np.bincount(labels[cluster_mask].astype(int)))\n",
        "        cluster_labels[j] = majority_label\n",
        "\n",
        "    # Assign cluster labels to data points\n",
        "    predicted_labels = np.array([cluster_labels[int(label)] for label in assigned_labels])\n",
        "\n",
        "    accuracy = np.sum(predicted_labels == labels.squeeze()) / len(labels)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "distance_functions = [euclidean_distance, cosine_similarity, jaccard_similarity]\n",
        "distance_function_names = ['Euclidean', 'Cosine', 'Jaccard']\n",
        "\n",
        "\n",
        "accuracies = {}\n",
        "\n",
        "for distance_function, distance_function_name in zip(distance_functions, distance_function_names):\n",
        "\n",
        "    accuracy = k_means_majority_vote(data, k, distance_function)\n",
        "    accuracies[distance_function_name] = accuracy\n",
        "\n",
        "for method, accuracy in accuracies.items():\n",
        "    print(f\"{method} K-means with Majority Vote - Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG_Ig0AxISSU",
        "outputId": "305d5858-c8ed-4152-fccb-78d4bde1e551"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean K-means with Majority Vote - Accuracy: 59.44%\n",
            "Cosine K-means with Majority Vote - Accuracy: 61.38%\n",
            "Jaccard K-means with Majority Vote - Accuracy: 60.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# K-means algorithm with stop criteria\n",
        "def k_means_stop_criteria(data, k, distance_function, max_iters=500, tolerance=1e-4):\n",
        "    n_samples, n_features = data.shape\n",
        "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
        "    assigned_labels = np.zeros(n_samples)\n",
        "\n",
        "    for iter_count in range(max_iters):\n",
        "        for i in range(n_samples):\n",
        "            distances = [distance_function(data[i], centroid) for centroid in centroids]\n",
        "            assigned_labels[i] = np.argmin(distances)\n",
        "\n",
        "        new_centroids = np.array([np.mean(data[assigned_labels == j], axis=0) for j in range(k)])\n",
        "\n",
        "        # Check stop criteria\n",
        "        if np.all(np.abs(new_centroids - centroids) < tolerance):\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    sse = sum([distance_function(data[i], centroids[int(assigned_labels[i])])**2 for i in range(n_samples)])\n",
        "\n",
        "    return assigned_labels, centroids, iter_count + 1, sse\n",
        "\n",
        "\n",
        "distance_functions = [euclidean_distance, cosine_similarity, jaccard_similarity]\n",
        "distance_function_names = ['Euclidean', 'Cosine', 'Jaccard']\n",
        "results = {}\n",
        "\n",
        "# Apply K-means algorithm with stop criteria for each distance function\n",
        "for distance_function, distance_function_name in zip(distance_functions, distance_function_names):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Run K-means with stop criteria\n",
        "    cluster_labels, cluster_centroids, num_iterations, sse = k_means_stop_criteria(data, k, distance_function)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Store information in the dictionary\n",
        "    results[distance_function_name] = {\n",
        "        'Cluster Labels': cluster_labels,\n",
        "        'Centroids': cluster_centroids,\n",
        "        'Num Iterations': num_iterations,\n",
        "        'SSE': sse,\n",
        "        'Time to Converge': end_time - start_time\n",
        "    }\n",
        "\n",
        "# Display results\n",
        "for method, result in results.items():\n",
        "    print(f\"{method} K-means - Iterations: {result['Num Iterations']}, SSE: {result['SSE']:.2f}, Time to Converge: {result['Time to Converge']:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoHUN0myIUmP",
        "outputId": "c1986809-68fa-4a6a-b928-3f70ae530058"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean K-means - Iterations: 31, SSE: 25323841391.58, Time to Converge: 28.6574 seconds\n",
            "Cosine K-means - Iterations: 97, SSE: 681.95, Time to Converge: 143.6564 seconds\n",
            "Jaccard K-means - Iterations: 151, SSE: 3660.40, Time to Converge: 284.2213 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-means algorithm with stop criteria\n",
        "def k_means_stop_criteria(data, k, distance_function, max_iters=100, tolerance=1e-4):\n",
        "    n_samples, n_features = data.shape\n",
        "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
        "    assigned_labels = np.zeros(n_samples)\n",
        "\n",
        "    for iter_count in range(max_iters):\n",
        "        for i in range(n_samples):\n",
        "            distances = [distance_function(data[i], centroid) for centroid in centroids]\n",
        "            assigned_labels[i] = np.argmin(distances)\n",
        "\n",
        "        new_centroids = np.array([np.mean(data[assigned_labels == j], axis=0) for j in range(k)])\n",
        "\n",
        "        # Check stop criteria\n",
        "        if np.all(np.abs(new_centroids - centroids) < tolerance):\n",
        "            break\n",
        "\n",
        "        # Update centroids for the next iteration\n",
        "        centroids = new_centroids\n",
        "\n",
        "\n",
        "    sse = sum([distance_function(data[i], centroids[int(assigned_labels[i])])**2 for i in range(n_samples)])\n",
        "\n",
        "    return assigned_labels, centroids, iter_count + 1, sse\n",
        "\n",
        "\n",
        "distance_functions = [euclidean_distance, cosine_similarity, jaccard_similarity]\n",
        "distance_function_names = ['Euclidean', 'Cosine', 'Jaccard']\n",
        "\n",
        "\n",
        "sse_results = {}\n",
        "\n",
        "for distance_function, distance_function_name in zip(distance_functions, distance_function_names):\n",
        "    # Run K-means with stop criteria\n",
        "    cluster_labels, cluster_centroids, num_iterations, sse = k_means_stop_criteria(data, k, distance_function)\n",
        "\n",
        "    sse_results[distance_function_name] = sse\n",
        "\n",
        "# Display SSEs\n",
        "for method, sse in sse_results.items():\n",
        "    print(f\"{method} K-means - SSE: {sse:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITHUHAH1IW5X",
        "outputId": "3b4684bf-9a82-44a5-8b04-f030955d6bea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean K-means - SSE: 25374322013.93\n",
            "Cosine K-means - SSE: 681.87\n",
            "Jaccard K-means - SSE: 3729.36\n"
          ]
        }
      ]
    }
  ]
}